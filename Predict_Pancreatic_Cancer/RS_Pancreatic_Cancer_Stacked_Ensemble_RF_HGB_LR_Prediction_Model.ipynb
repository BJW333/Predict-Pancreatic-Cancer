{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Pancreatic Cancer Predictive Model\n",
    "This program trains a model to predict pancreatic cancer using urinary biomarkers.\n",
    "The dataset is from the study \"Urinary Biomarkers for Pancreatic Cancer\" by Debernardi et al. (2020).\n",
    "\n",
    "The diagnosis classes are defined as:\n",
    "    1: Control (No Pancreatic Disease)\n",
    "    2: Benign Hepatobiliary Disease (including chronic pancreatitis)\n",
    "    3: Pancreatic Ductal Adenocarcinoma (Pancreatic Cancer)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import random\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Global Settings\n",
    "SCRIPT_DIR = Path.cwd() # if using jupyter notebook, use this line\n",
    "#SCRIPT_DIR = Path(__file__).parent  # Directory of this script. if using reg .py use this line\n",
    "\n",
    "MODEL_FILENAME = 'pancreatic_cancer_RF_HGB_LR_predictor.pkl'\n",
    "MODEL_PATH = SCRIPT_DIR / MODEL_FILENAME\n",
    "print(\"Model path:\", MODEL_PATH)\n",
    "print(\"Script folder:\", SCRIPT_DIR)\n",
    "\n",
    "#class labels for readability.\n",
    "CLASS_LABELS = {\n",
    "    1: \"Control (No Pancreatic Disease)\",\n",
    "    2: \"Benign Hepatobiliary Disease\",\n",
    "    3: \"Pancreatic Ductal Adenocarcinoma\"\n",
    "}\n",
    "\n",
    "#suppress warnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#Data Loading and Preprocessing\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Downloads (if necessary) and loads the dataset cleans and preprocesses it\n",
    "    \n",
    "    Returns:\n",
    "        df (DataFrame): The preprocessed dataset with sample_id set as identifyer\n",
    "    \"\"\"\n",
    "    #download dataset using Kaggle.\n",
    "    data_source = kagglehub.dataset_download(\"johnjdavisiv/urinary-biomarkers-for-pancreatic-cancer\")\n",
    "    print('\\nData source imported:', data_source)\n",
    "    \n",
    "    #set the path to the downloaded dataset.\n",
    "    data_dir = Path('/Users/blakeweiss/.cache/kagglehub/datasets/johnjdavisiv/urinary-biomarkers-for-pancreatic-cancer/versions/1')\n",
    "    data_file = data_dir / 'Debernardi et al 2020 data.csv'\n",
    "    \n",
    "    if not data_file.exists():\n",
    "        raise FileNotFoundError(f\"Data file not found: {data_file}\\nPlease check the path and ensure the dataset is correctly downloaded.\")\n",
    "    \n",
    "    #read CSV data into a DataFrame\n",
    "    df = pd.read_csv(data_file)\n",
    "    \n",
    "    #print basic information.\n",
    "    print(df.head(10))\n",
    "    print(\"Data shape:\", df.shape)\n",
    "    print(\"\\nMissing values per column:\\n\", df.isna().sum())\n",
    "    \n",
    "    #preserve 'sample_id' by setting it as the index/identifer\n",
    "    #drop other columns that are not useful (ex, stage, benign_sample_diagnosis, sample_origin)\n",
    "    #and drop 'patient_cohort' since the cohort doesnt matter\n",
    "    df.set_index('sample_id', inplace=True)\n",
    "    #data values that are not being passed and are being dropped due to many reasons\n",
    "    df.drop(['stage', 'sample_origin', 'benign_sample_diagnosis', 'patient_cohort'], axis=1, inplace=True) \n",
    "    \n",
    "\n",
    "    #mean imputation: fill missing values in key data biomarkers using the actual mean of said data markers\n",
    "    #this is meant to preserve accuracy of the model. and input missing values with means of said values \n",
    "    #print(\"Using mean imputation for missing values\") #debugging line\n",
    "    df['plasma_CA19_9'].fillna(df['plasma_CA19_9'].mean(), inplace=True)\n",
    "    df['REG1A'].fillna(df['REG1A'].mean(), inplace=True)\n",
    "\n",
    "    print(\"\\nMissing values after cleaning:\\n\", df.isna().sum())\n",
    "    \n",
    "    #convert categorical text to numeric.\n",
    "    df['sex'] = df['sex'].map({'M': 1, 'F': 0})\n",
    "    #df['sample_origin'] = df['sample_origin'].map({'BPTB': 0, 'LIV': 1, 'ESP': 2, 'UCL': 3}) \n",
    "    #this line above mapped sample_origin to numbers corrsponding to orgins but was not used in the model.\n",
    "    #commented above line out because to do something simlar to feature importance visualizations had to drop sample_origin from dataset.\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#model training and evaluation and hyperparameter tuning\n",
    "def train_tuned_model(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Grid‐search to prune the tree and return the best pipeline.\"\"\"\n",
    "\n",
    "    #build the base pipeline\n",
    "    stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(random_state=0)),\n",
    "        ('hgb', HistGradientBoostingClassifier(random_state=0))\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', stack)           \n",
    "    ])\n",
    "\n",
    "    \n",
    "    param_dist = { \n",
    "        #tune the base learners\n",
    "        #tune the final logistic-regression C \n",
    "        'classifier__final_estimator__C': [0.01, 0.1, 1, 10, 100, 150, 200, 250],\n",
    "        \n",
    "        #tune how many trees in your RF base learner\n",
    "        'classifier__rf__n_estimators': [50, 100, 200, 300, 400],\n",
    "        \n",
    "        #tune how many boosting iterations in HistGB\n",
    "        'classifier__hgb__max_iter': [50, 100, 150, 200, 250, 300],\n",
    "\n",
    "\n",
    "        #max_depth for random forest and hist gradient boosting \n",
    "        'classifier__rf__max_depth': [None, 3, 5, 10, 15, 20, 25, 30], \n",
    "        'classifier__hgb__max_depth': [None, 3, 5, 10, 15, 20, 25, 30],\n",
    "\n",
    "        #min_samples_split and min_samples_leaf\n",
    "        'classifier__rf__min_samples_split': [2, 5, 10, 20, 50],\n",
    "        'classifier__rf__min_samples_leaf': [1, 2, 5, 10, 20],\n",
    "        'classifier__hgb__min_samples_leaf': [1, 2, 5, 10, 20],\n",
    "    }\n",
    "\n",
    "    grid = RandomizedSearchCV( \n",
    "        estimator=pipe,                 #use the pipeline without the imputer within the pipeline for mean imputation refer back to thoughts in loading \n",
    "        param_distributions=param_dist, #use param_dist\n",
    "        n_iter=2000,#1500                #num of random samples to draw from the parameter space\n",
    "        cv=5,                           #5 fold cross validation\n",
    "        scoring='accuracy',             #eval accuracy\n",
    "        n_jobs=-1,                   #use all available CPU cores\n",
    "        random_state=0,                #for reproducible random sampling aka if ranstate = 0 and it is run again it will be the same aka \n",
    "        #random_state=42 it will output different results this is very complex refer back to documentation and notes\n",
    "        verbose=1                       \n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    #fit the grid search\n",
    "    print(f\"Starting RandomizedSearchCV with {grid.n_iter} iterations...\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"RandomizedSearchCV complete.\")\n",
    "    \n",
    "    #Report best parameters and CV score\n",
    "    print(\"Best hyperparameters:\", grid.best_params_)\n",
    "    \n",
    "    #this is performance on the training data (evaluated via CV folds)\n",
    "    #not the final evaluation on your separate unseen X_test which is reported by best_pipe.score(X_test, y_test)\n",
    "    print(f\"\\nBest CV accuracy: {grid.best_score_:.3f}\")\n",
    "\n",
    "    #Evaluate on the test set\n",
    "    best_pipe = grid.best_estimator_\n",
    "    test_acc = best_pipe.score(X_test, y_test)\n",
    "    print(f\"Test accuracy (tuned): {test_acc:.3f}\")\n",
    "\n",
    "    #detailed classification report\n",
    "    y_pred = best_pipe.predict(X_test)\n",
    "    print(\"\\nClassification Report (tuned):\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return best_pipe\n",
    "\n",
    "\n",
    "#Visualization Functions - should all work but cation is advised because had to just learn how to plot this stuff\n",
    "def visualize_results(df, X, y, y_test, y_pred, pipeline):\n",
    "    \"\"\"Generates refined plots for data exploration and model evaluation\"\"\"\n",
    "    \n",
    "    #set a consistent overall seaborn style.\n",
    "    sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "    \n",
    "    \n",
    "    #Visualize the distribution of the diagnous variable classes\n",
    "    #print check class distribution\n",
    "    #print(df['diagnosis'].value_counts()) #debugging line\n",
    "    #visualize it\n",
    "    sns.countplot(x='diagnosis', data=df)\n",
    "    plt.title('Distribution of Diagnosis Classes')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    #=========================================================================================================\n",
    "    #BOX PLOTS OF BIOMARKERS BY DIAGNOSIS\n",
    "    #=========================================================================================================\n",
    "\n",
    "    #Box Plot for plasma_CA19_9 by diagnosis\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    data_to_plot = [df[df['diagnosis'] == label]['plasma_CA19_9'] \n",
    "                    for label in sorted(df['diagnosis'].unique())]\n",
    "    plt.boxplot(data_to_plot, labels=[CLASS_LABELS.get(label, label) \n",
    "                                      for label in sorted(df['diagnosis'].unique())])\n",
    "    plt.title('plasma_CA19_9 Levels by Diagnosis')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('plasma_CA19_9 Level')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Box Plot for REG1A by diagnosis\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    data_to_plot = [df[df['diagnosis'] == label]['REG1A'] \n",
    "                    for label in sorted(df['diagnosis'].unique())]\n",
    "    plt.boxplot(data_to_plot, labels=[CLASS_LABELS.get(label, label) \n",
    "                                      for label in sorted(df['diagnosis'].unique())])\n",
    "    plt.title('REG1A Levels by Diagnosis')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('REG1A Level')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Box plot for LYVE1 by diagnosis\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    data_to_plot = [df[df['diagnosis'] == label]['LYVE1'] \n",
    "                    for label in sorted(df['diagnosis'].unique())]\n",
    "    plt.boxplot(data_to_plot, labels=[CLASS_LABELS.get(label, label) \n",
    "                                      for label in sorted(df['diagnosis'].unique())])\n",
    "    plt.title('LYVE1 Levels by Diagnosis')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('LYVE1 Level')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Box plot for REG1B by diagnosis\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    data_to_plot = [df[df['diagnosis'] == label]['REG1B'] \n",
    "                    for label in sorted(df['diagnosis'].unique())]\n",
    "    plt.boxplot(data_to_plot, labels=[CLASS_LABELS.get(label, label) \n",
    "                                      for label in sorted(df['diagnosis'].unique())])\n",
    "    plt.title('REG1B Levels by Diagnosis')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('REG1B Level')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Box plot for TFF1 by diagnosis\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    data_to_plot = [df[df['diagnosis'] == label]['TFF1'] \n",
    "                    for label in sorted(df['diagnosis'].unique())]\n",
    "    plt.boxplot(data_to_plot, labels=[CLASS_LABELS.get(label, label) \n",
    "                                      for label in sorted(df['diagnosis'].unique())])\n",
    "    plt.title('TFF1 Levels by Diagnosis')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('TFF1 Level')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Box plot for creatinine by diagnosis\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    data_to_plot = [df[df['diagnosis'] == label]['creatinine'] \n",
    "                    for label in sorted(df['diagnosis'].unique())]\n",
    "    plt.boxplot(data_to_plot, labels=[CLASS_LABELS.get(label, label) \n",
    "                                      for label in sorted(df['diagnosis'].unique())])\n",
    "    plt.title('creatinine Levels by Diagnosis')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('creatinine Level')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #=========================================================================================================\n",
    "    \n",
    "    #Confusion Matrix Heatmap\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    ax = sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                      xticklabels=[CLASS_LABELS.get(cls, str(cls)) for cls in sorted(y.unique())],\n",
    "                      yticklabels=[CLASS_LABELS.get(cls, str(cls)) for cls in sorted(y.unique())])\n",
    "    plt.xlabel(\"Predicted Diagnosis\", fontsize=12)\n",
    "    plt.ylabel(\"True Diagnosis\", fontsize=12)\n",
    "    plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    #Feature Importance using Permutation Importance - shows the importance of each feature/datapoint in the model\n",
    "    print(\"\\nComputing permutation importances\")\n",
    "    X_test = X.loc[y_test.index]\n",
    "    perm = permutation_importance(\n",
    "        pipeline,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        n_repeats=10,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    fi = pd.DataFrame({\n",
    "        'feature': X_test.columns,\n",
    "        'importance': perm.importances_mean\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    #plot permutation importances\n",
    "    print(fi)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(fi['feature'], fi['importance'])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Mean decrease in accuracy\")\n",
    "    plt.title(\"Feature Importances (Permutation)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "#Model Persistence and Inference\n",
    "def save_model(pipeline):\n",
    "    \"\"\"Saves the trained model pipeline to disk.\"\"\"\n",
    "    joblib.dump(pipeline, MODEL_PATH)\n",
    "    print(f'\\nModel saved as {MODEL_PATH}')\n",
    "\n",
    "\n",
    "#this function is not utlized currently anywhere \n",
    "#because i didnt seperate the main function and test random patients parts of the main function\n",
    "def predict_cancer(input_data): \n",
    "    \"\"\"\n",
    "    Diagnose pancreatic cancer from input data\n",
    "    Parameters:\n",
    "        input_data (dict or pd.DataFrame): Data for one patient. The keys must match the training features.\n",
    "        \n",
    "    Returns:\n",
    "        prediction (int): Predicted diagnosis.\n",
    "    \"\"\"\n",
    "    if isinstance(input_data, dict):\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "    else:\n",
    "        input_df = input_data.copy()\n",
    "\n",
    "    #load the saved model.\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    prediction = model.predict(input_df)\n",
    "    #print(\"prediction:\", prediction) #debugging line\n",
    "    return prediction[0]\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = load_and_preprocess_data()\n",
    "    \n",
    "    #define features and target.\n",
    "    target = 'diagnosis'\n",
    "    X = df.drop(target, axis=1)  #sample_id is now the identifyer and is not used as a feature.\n",
    "    y = df[target]\n",
    "    \n",
    "    #train and evaluate the model also split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    #hyperparameter tuning + training\n",
    "    pipeline = train_tuned_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    #get predictions on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    #save the trained model.\n",
    "    save_model(pipeline)\n",
    "    \n",
    "    #run visualizations and statistical tests.\n",
    "    visualize_results(df, X, y, y_test, y_pred, pipeline)\n",
    "    \n",
    "    #ANOVA TESTS AND BOX PLOTS - ANOVA tells you if a biomarker’s mean value differs significantly across diagnosis groups (Control, Benign, Cancer).\n",
    "    biomarkers = ['plasma_CA19_9', 'REG1A', 'LYVE1', 'REG1B', 'TFF1', 'creatinine']\n",
    "\n",
    "    for biomarker in biomarkers:\n",
    "        #ANOVA tests\n",
    "        groups = [group[biomarker].dropna().values for _, group in df.groupby('diagnosis')]\n",
    "        f_stat, p_val = f_oneway(*groups)\n",
    "        print(f\"\\nANOVA for {biomarker}: F = {f_stat:.2f}, p = {p_val:.4g}\")\n",
    "        \n",
    "        #Boxplot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.boxplot(x='diagnosis', y=biomarker, data=df)\n",
    "        plt.title(f'(ANOVA) {biomarker} Levels by Diagnosis (p = {p_val:.3g})')\n",
    "        plt.xlabel(\"Diagnosis\")\n",
    "        plt.ylabel(f\"{biomarker} Level\")\n",
    "        plt.xticks([0, 1, 2], [CLASS_LABELS[i+1] for i in range(3)], rotation=30)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "#=========================================================================================================\n",
    "#=========================================================================================================\n",
    "#=========================================================================================================\n",
    "\n",
    "    \n",
    "    print(\"\\n=========================Seperate Testing Section=========================\")\n",
    "    print(\"Randomly select patients from the test set to evaluate the model\")\n",
    "    \n",
    "    # Combine X_test and y_test into a DataFrame to sample from test set only\n",
    "    test_df = X_test.copy()\n",
    "    test_df['diagnosis'] = y_test\n",
    "    #print(\"Test set shape:\", test_df.shape)\n",
    "    #print(\"Test set head:\\n\", test_df.head())\n",
    "    \n",
    "    #randomly select number of test patients \n",
    "    numoftestpatients=random.randint(10, 60) #orignally set the last value to 75\n",
    "    \n",
    "    #old line to sample from the entire dataset (this causes issues use the test_df instead)\n",
    "    #random_samples = df.sample(n=numoftestpatients, random_state=42) \n",
    "    \n",
    "    #new line to sample from the test set only\n",
    "    random_samples = test_df.sample(n=numoftestpatients, random_state=42) \n",
    "\n",
    "    print(\"The amount of randomly selected patients are:\", numoftestpatients)\n",
    "    true_diagnoses = random_samples['diagnosis'].tolist()\n",
    "    sample_inputs = random_samples.drop('diagnosis', axis=1) #drop the diagnosis column for prediction\n",
    "        \n",
    "    #predict diagnoses for the random patients\n",
    "    predictions = pipeline.predict(sample_inputs)\n",
    "    \n",
    "    \n",
    "    #print overall accuracy of the model on the test set\n",
    "    #accuracy over the entire 20% test set (the gold standard performance metric).\n",
    "    print(\"\\nAccuracy over the entire 20% test set (the gold standard performance metric).\")\n",
    "    overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Overall Accuracy on Test Set: {overall_accuracy:.3f}\")\n",
    "    \n",
    "\n",
    "    predicted_labels = [CLASS_LABELS.get(pred, pred) for pred in predictions]\n",
    "    true_labels = [CLASS_LABELS.get(label, label) for label in true_diagnoses]\n",
    "    \n",
    "    #print the results for the randomly selected patients in terminal\n",
    "    print(\"\\n\\nRandomly selected patients and their predicted diagnoses:\")\n",
    "    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "    for idx, true_label, predicted_label in zip(random_samples.index, true_labels, predicted_labels):\n",
    "        if predicted_label == true_label:\n",
    "            was_prediction_the_correct = True\n",
    "        else:\n",
    "            was_prediction_the_correct = False\n",
    "        \n",
    "        print(f\"Patient {idx}: | Predicted Diagnosis: {predicted_label} | True Diagnosis: {true_label} | {was_prediction_the_correct}\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    #Accuracy over a random subset of the test set — a quick spot check.\n",
    "    #this is not the same as the overall accuracy of the model on the test set.\n",
    "    #this is a quick spot check to see if the model is working correctly.\n",
    "    print(\"\\n\\nAccuracy over a random subset of the test set — a quick spot check.\")\n",
    "    accuracy = accuracy_score(true_diagnoses, predictions)\n",
    "    print(f\"Overall Accuracy on Random Samples: {accuracy:.3f}\")\n",
    "    \n",
    "    \n",
    "#=========================================================================================================\n",
    "#======================PLOT THE PREDICTIONS FOR THE RANDOMLY SELECTED PATIENTS============================\n",
    "#=========================================================================================================\n",
    "\n",
    "    #prepare patient info\n",
    "    predicted_labels = [CLASS_LABELS.get(pred, pred) for pred in predictions]\n",
    "    true_labels = [CLASS_LABELS.get(label, label) for label in true_diagnoses]\n",
    "\n",
    "    patient_ids = [f\"Patient {idx}\" for idx in random_samples.index]\n",
    "    correctness = [pred == true for pred, true in zip(predicted_labels, true_labels)]\n",
    "    colors = [\"green\" if correct else \"red\" for correct in correctness]\n",
    "\n",
    "    #use constant bar length for display\n",
    "    bar_lengths = [1] * len(patient_ids)\n",
    "    y_pos = np.arange(len(patient_ids))\n",
    "\n",
    "    #plot horizontal bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 0.4 * len(patient_ids)))\n",
    "\n",
    "    ax.barh(y_pos, bar_lengths, color=colors, edgecolor='black')\n",
    "\n",
    "    #add text labels with predicted and true diagnosis\n",
    "    for i, (pid, pred, true, correct) in enumerate(zip(patient_ids, predicted_labels, true_labels, correctness)):\n",
    "        status = \"Correct\" if correct else \"Incorrect\"\n",
    "        label = f\"Predicted: {pred} | True Diagnosis: {true} | {status}\"\n",
    "        ax.text(0.02, i, f\"{pid}: {label}\", va='center', fontsize=9, color='white' if correct else 'black', fontfamily='monospace')\n",
    "\n",
    "    #format\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(patient_ids)\n",
    "    ax.set_xticks([])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlim(0, 1.05)\n",
    "    ax.set_title(f\"Prediction per Randomly Selected Patient from Test Set. \\nAmount of Selected Patients: {numoftestpatients} \\nOverall Accuracy on Random Samples: {accuracy:.3f}\", fontsize=14)\n",
    "    ax.axis('off')\n",
    "\n",
    "    plt.savefig(SCRIPT_DIR / \"patient_predictions.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
